{
  "title": "LifeLearner: Hardware-Aware Meta Continual Learning System for Embedded Computing Platforms",
  "abstract": "Continual Learning (CL) allows applications such as user personalization and household robots to learn on the fly and adapt to context. This is an important feature when context, actions, and users change. However, enabling CL on resource-constrained embedded systems is challenging due to the limited labeled data, memory, and computing capacity. In this paper, we propose LifeLearner, a hardware-aware meta continual learning system that drastically optimizes system resources (lower memory, latency, energy consumption) while ensuring high accuracy. Specifically, we (1) exploit meta-learning and rehearsal strategies to explicitly cope with data scarcity issues and ensure high accuracy, (2) effectively combine lossless and lossy compression to significantly reduce the resource requirements of CL and rehearsal samples, and (3) developed hardware-aware system on embedded and IoT platforms considering the hardware characteristics. As a result, LifeLearner achieves near-optimal CL performance, falling short by only 2.8% on accuracy compared to an Oracle baseline. With respect to the state-of-the-art (SOTA) Meta CL method, LifeLearner drastically reduces the memory footprint (by 178.7\u00d7), end-to-end latency by 80.8-94.2%, and energy consumption by 80.9-94.2%. In addition, we successfully deployed LifeLearner on two edge devices and a microcontroller unit, thereby enabling efficient CL on resource-constrained platforms where it would be impractical to run SOTA methods and the far-reaching deployment of adaptable CL in a ubiquitous manner. Code is available at https://github.com/theyoungkwon/LifeLearner. \u2022 Computer systems organization \u2192 Embedded and cyber-physical systems; \u2022 Human-centered computing \u2192 Ubiquitous and mobile computing.",
  "authors": [
    {
      "name": "Chauhan",
      "email": "j.chauhan@soton.ac.uk",
      "institutions": [
        {
          "institution_name": ""
        }
      ]
    },
    {
      "name": "Venieris",
      "email": "s.venieris@samsung.com",
      "institutions": [
        {
          "institution_name": "Samsung AI Center"
        }
      ]
    }
  ],
  "keywords": [
    "Continual Learning",
    "Meta Learning",
    "On-device Training",
    "Latent Replay",
    "Product Quantization",
    "Edge Computing",
    "Microcontrollers"
  ],
  "references": [
    "Continuous Adaptation via Meta-Learning in Nonstationary and Competitive Environments",
    "Memory Aware Synapses: Learning what (not) to forget",
    "Learning to Continually Learn",
    "TinyTL: Reduce Memory, Not Parameters for Efficient On-Device Learning",
    null,
    "End-to-End Incremental Learning",
    "Con-tAuth: Continual Learning Framework for Behavioral-based User Authentication",
    "Exploring On-Device Learning Using Few Shots for Audio Classification",
    "ActNN: Reducing Training Memory Footprint via 2-Bit Activation Compressed Training",
    "TensorFlow Lite Micro: Embedded Machine Learning for TinyML Systems",
    "A Continual Learning Survey: Defying Forgetting in Classification Tasks",
    "COCOA: Cross Modality Contrastive Learning for Sensor Data",
    "RF-Net: A Unified Meta-Learning Framework for RF-Enabled One-Shot Human Activity Recognition",
    "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale",
    "AC-GC: Lossy Activation Compression with Guaranteed Convergence",
    "Model-agnostic metalearning for fast adaptation of deep networks",
    "Memory-Efficient DNN Training on Mobile Devices",
    "MetaSense: Few-Shot Adaptation to Untrained Conditions in Deep Mobile Sensing",
    "A Broader Study of Cross-Domain Few-Shot Learning",
    "Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding",
    "REMIND Your Neural Network to Prevent Catastrophic Forgetting",
    "Deep Residual Learning for Image Recognition",
    "Sparse Bitmap Compression for Memory-Efficient Training on the Edge",
    "Meta-Learning in Neural Networks: A Survey",
    "Pushing the Limits of Simple Pipelines for Few-Shot Learning: External Data and Fine-Tuning Make a Difference",
    "SwapAdvisor: Pushing Deep Learning Beyond the GPU Memory Limit via Smart Swapping",
    "ElasticTrainer: Speeding Up On-Device Training with Runtime Elastic Tensor Selection",
    "GPipe: Efficient Training of Giant Neural Networks Using Pipeline Parallelism",
    "Compacting, Picking and Growing for Unforgetting Continual Learning",
    "Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference",
    "Checkmate: Breaking the Memory Wall with Optimal Tensor Rematerialization",
    "Meta-Learning Representations for Continual Learning",
    "Band: Coordinated Multi-DNN Inference on Heterogeneous Mobile Processors",
    "Continual learning in sensor-based human activity recognition: An empirical benchmark analysis",
    "Billion-scale similarity search with GPUs",
    "Product Quantization for Nearest Neighbor Search",
    "Adam: A Method for Stochastic Optimization",
    "Dynamic Tensor Rematerialization",
    "Overcoming catastrophic forgetting in neural networks",
    "Lane Compression: A Lightweight Lossless Compression Method for Machine Learning on Embedded Systems",
    "Exploring System Performance of Continual Learning for Mobile and Embedded Sensing Applications",
    "FastICARL: Fast Incremental Classifier and Representation Learning with Efficient Budget Allocation in Audio Sensing Applications",
    "YONO: Modeling Multiple Heterogeneous Neural Networks on Microcontrollers",
    "Human-level concept learning through probabilistic program induction",
    "GazeGraph: Graph-Based Few-Shot Cognitive Context Sensing from Human Visual Behavior",
    "A survey of mobile phone sensing",
    "uNAS: Constrained Neural Architecture Search for Microcontrollers",
    "MCUNet: Tiny Deep Learning on IoT Devices",
    "On-Device Training Under 256KB Memory",
    "BlastNet: Exploiting Duo-Blocks for Cross-Processor Real-Time DNN Inference",
    "RT-MDL: Supporting Real-Time Mixed Deep Learning Tasks on Edge Platforms",
    "AutoCompress: An Automatic DNN Structured Pruning Framework for Ultra-High Compression Rates",
    "GACT: Activation Compressed Training for Generic Network Architectures",
    "ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design",
    "Why there are complementary learning systems in the hippocampus and neocortex: Insights from the successes and failures of connectionist models of learning and memory",
    "Catastrophic Interference in Connectionist Networks: The Sequential Learning Problem",
    "Essentials for Class Incremental Learning",
    "Deep Online Learning Via Meta-Learning: Continual Adaptation for Model-Based RL",
    "A Survey on Transfer Learning",
    "Continual lifelong learning with neural networks: A review",
    "PyTorch: An Imperative Style, High-Performance Deep Learning Library",
    "POET: Training Neural Networks on Tiny Devices with Integrated Rematerialization and Paging",
    "Latent Replay for Real-Time Continual Learning",
    "PROS: An Efficient Pattern-Driven Compressive Sensing Framework for Low-Power Biopotential-Based Wearables with on-Chip Intelligence",
    "Computationally Budgeted Continual Learning: What Does Matter?",
    "Deep Learning for Audio Signal Processing",
    "P-Meta: Towards On-Device Deep Model Adaptation",
    "Rapid Learning or Feature Reuse? Towards Understanding the Effectiveness of MAML",
    "XNOR-Net: ImageNet Classification Using Binary Convolutional Neural Networks",
    "iCaRL: Incremental classifier and representation learning",
    "MobileNetV2: Inverted Residuals and Linear Bottlenecks",
    "Progress & Compress: A Scalable Framework for Continual Learning",
    "Prototypical Networks for Few-shot Learning",
    "Training with Quantization Noise for Extreme Model Compression",
    "And the Bit Goes Down: Revisiting the Quantization of Neural Networks",
    "Deep Learning on Microcontrollers: A Study on Deployment Costs and Challenges",
    "Efficient Processing of Deep Neural Networks: A Tutorial and Survey",
    "Meta-Dataset: A Dataset of Datasets for Learning to Learn from Few Examples",
    "Attention is All you Need",
    "Matching Networks for One Shot Learning",
    "Melon: Breaking the Memory Wall for Resource-Efficient On-Device Machine Learning",
    "Large Scale Incremental Learning",
    "OneFi: One-Shot Recognition for Unseen Gesture via COTS WiFi",
    "Deep Compressive Offloading: Speeding up Neural Network Inference by Trading Edge Computation for Network Latency",
    "Lifelong Learning with Dynamically Expandable Networks",
    "Continual Learning Through Synaptic Intelligence",
    "MDLdroidLite: A Release-and-Inhibit Control Approach to Resource-Efficient Deep Neural Networks on Mobile Devices"
  ],
  "full_text": "With the rise of embedded and Internet of Things (IoT) devices, the adoption of deep neural networks (DNN) has revolutionized various applications ranging from computer vision  Many CL approaches have been proposed in the literature, including regularization-based  Another stream of work has recently attempted to utilize metalearning  Additionally, state-of-the-art (SOTA) Meta CL methods, OML+AIM and ANML+AIM  To address the aforementioned limitations, we develop Life-Learner, the first hardware-aware system that fully enables dataand memory-efficient CL on the constrained edge and IoT devices. First, contrary to the existing Meta CL methods that primarily rely on regularization and suffer from accuracy loss, we introduce rehearsal-based Meta CL; we co-design meta-learning with an efficient rehearsal strategy, enabling LifeLearner to rapidly learn new classes using only a few samples while alleviating catastrophic forgetting of the already learned classes upon deployment (Section 3.1). Second, we propose a CL-tailored algorithm/software co-design approach that minimizes the on-device resource overheads of CL. At the algorithmic level, we design a latent replay scheme, where rehearsal samples are extracted from an intermediate layer of the target DNN instead of holding copies of raw inputs. By strategically selecting the rehearsal layer for high compressibility, we facilitate the subsequent compression of rehearsal samples, enabling their efficient storage on-device. Besides, based on an observation that latent replays are sparse, we further design a novel Compression Module via an intelligent combination of lossless compression to utilize sparsity and lossy compression to yield a high compression rate, fast encoding and decoding, and minimal resource usage (Section 3.2). Finally, we develop our hardware-aware system by employing hardware-friendly optimization techniques and considering the unique characteristics of hardware (e.g., write operation on Flash of IoT devices is costly during runtime) to optimize the runtime efficiency of CL operations on-device (Section 4). We make the following key contributions: (1) A novel Meta CL method comprises a rehearsal strategy that alleviates catastrophic forgetting and a deployment-time inner-and outer-loop training structure that achieves both fast adaptation to new classes and refreshing of already learned classes. Life-Learner achieves previously unattainable levels of on-device accuracy, outperforming all existing Meta CL methods by 4.1-16.1% on image and audio datasets, while being within 2.8% of an oracle. (2) A new algorithm/software co-design method that co-optimizes the rehearsal strategy and the compression pipeline to significantly reduce the resource requirements of CL and rehearsal samples. As a result, LifeLearner requires only 3.40-15.45 MB of memory and obtains a compression rate of 11.4-178.7\u00d7 compared to the SOTA Meta CL method, ANML+AIM. This allows LifeLearner to run on edge devices, something impossible for current SOTA methods due to their large memory requirements (>1.05 GB). (3) Our hardware-aware system implementation successfully deployed LifeLearner on two embedded devices (Jetson Nano and Raspberry Pi 3B+) and a microcontroller (STM32H747    The first group of approaches includes regularization-based methods  In this work, we opt to use a rehearsal-based method due to its primarily superior performance in CL settings and the avoidance of dynamic expansion of the model architecture during deployment, allowing us to apply system optimizations on the static computation graph of the model (see last paragraph of Section 4 for details). Given a single trajectory of samples from a stream of classes T , minimizing the CL loss of a DNN that is trained end-to-end is more challenging than conventional DNN training  (1) the forgetting problem incurred when learning a stream of different classes, (2) the issue with the lack of labeled samples, and (3) training DNNs is extremely sample-inefficient: the minimization problem requires multiple training epochs to converge to a reasonable solution. Specifically, many CL methods  To overcome the challenges mentioned thus far, researchers proposed a novel approach, Meta CL, that utilizes meta-learning in CL to enable data-efficient and fast adaptation to new classes and also attempts to alleviate forgetting of already learned classes through novel ways of regularization and/or modification of the model architecture  Although prior works in Meta CL enable CL with limited data samples, they have certain limitations. For example, Online-aware Meta-Learning (OML)  Scarce memory and compute resources are major bottlenecks in deploying DNNs on constrained embedded and IoT devices. In this context, researchers have largely focused on optimizing the inference stage (i.e., forward pass) by proposing lightweight DNN architectures  In addition, many works focus on reducing the overall system resources required for DNN training  In contrast to previous works, LifeLearner realizes efficient continual learning that was previously considered impractical for many embedded devices. By developing rehearsal-based Meta CL, effective algorithm/software co-design, and hardware-aware system implementation considering the unique characteristics of a wide range of embedded and IoT platforms (e.g., Jetson Nano, Pi 3B+, and STM32H747), LifeLearner yields both high accuracy and low resource overheads. LifeLearner leverages the idea of Meta CL and rehearsal-based learning and minimizes the system overheads on embedded devices. Life-Learner consists of two phases. The first phase, i.e., meta-training, is performed on a server to obtain a good weight initialization by utilizing meta-learning in the CL setup with a few samples. The second phase is meta-testing: a meta-trained model is deployed on embedded devices and learns new classes continually without forgetting previously learned classes. Additionally, as shown in Figure  (1) co-utilization of Meta CL and rehearsal strategy together with a deployment-time inner-and outer-loop optimization to resolve the accuracy degradation issue, (2) a design scheme that co-optimizes LifeLearner's rehearsal strategy and compression pipeline (Compression Module in Figure  Current Meta CL methods rely on regularization in order to minimize radical changes to the already trained weights when learning new classes. As such, given a small set of training data from a stream of classes, all samples are discarded once they have been used. However, recent results from the CL literature  In addition, existing Meta CL systems are limited by their sole use of inner-loop optimization during meta-testing. Instead, we construct a variant of the learning fast and slow weights approach: we utilize the samples of new classes during inner-loop updates to enable rapid adaptation to new classes, followed by outer-loop iterations with the rehearsal samples of the previously learned classes to alleviate catastrophic forgetting. System Overhead. Despite the learning benefits of our rehearsalbased Meta CL method (see Section 5.2 for details), it comes at a system cost. With respect to memory, the Replay Buffer has to store a number of representative samples for each of the already encountered classes, so that they can be fetched during meta-testing. With respect to computation, the samples have to be processed by the DNN with both forward and backward passes to perform CL. Unless alleviated, these overheads can lead to a sharp increase in storage and computational requirements, hindering its deployment on mobile and embedded devices, where continual learning is most needed. In the next section, we present LifeLearner's co-design approach for alleviating these system costs. To alleviate the system costs of rehearsal-based Meta CL and enable its deployment on resource-constrained devices, we present an algorithm-software co-design method, optimized for Continual Learning. At the algorithmic level, we design a rehearsal strategy that minimizes the computational overhead while maximizing the compressibility of the rehearsal samples. At the software level, we design a two-stage Compression Module that enables the efficient compression, storage and decompression of rehearsal samples, while inducing minimal on-device resource usage. methods constitutes the form of the rehearsal samples. A standard approach followed by many CL methods  On the memory front, we make the following observation. In DNN training, the activations for each layer are saved during the forward propagation so that those activations are utilized for computing the gradients during the backward propagation. As in  We now introduce the Compression Module that is responsible for i) compressing rehearsal samples (i.e., latent activations in our work) when new classes are encountered and storing them in the Replay Buffer, and ii) fetching and decompressing them to perform CL at runtime. This component comprises two stages: sparse bitmap compression and product quantization (PQ). Sparse Bitmap Compression. To leverage the sparsity of our latent replays for efficient storage, we employ sparse bitmap compression  Figure  For compression, the PQ encoder applies PQ to the non-zero activations v \u2208 R \ud835\udc51 that are already filtered out by the first-stage sparse bitmap compression. We use 1 byte to store each PQ index and set \ud835\udc51/\ud835\udc60 = {128, 32, 8} (length of each sub-vector). Then, each sub-vector of length \ud835\udc51/\ud835\udc60 containing 32-bit floats is encoded to a 1-byte PQ index via our PQ encoder for more analysis regarding hyper-parameters). LifeLearner learns the PQ codebook offline using the latent activations during the meta-training phase, which is then stored on-device. For decompression, the PQ decoder reconstructs the non-zero activations v \u2032 using the stored PQ indices and the PQ codebook. Finally, as in Algorithm 2 (see Lines 7, 9, and 10), our compression module is seamlessly incorporated in the inner-and outer-loop optimization of LifeLearner, enabling on-the-fly compression of the latent activations during deployment.  Having described the main components of LifeLearner we now present the complete meta-training and meta-testing procedures that take place offline and online, respectively. Meta-Training Procedure. Algorithm 1 shows the procedure of meta-training of Rehearsal-based Meta CL, LifeLearner. Firstly, the meta-training process of rehearsal-based Meta CL is the same as that of Meta CL  Meta-Testing Procedure. After executing the meta-training phase on a server, our system is deployed on resource-constrained devices and evaluated on its ability to learn unseen classes in the meta-testing phase. Algorithm 2 shows the meta-testing phase of the rehearsal-based Meta CL. In prior Meta CL, the meta-testing procedure contains only inner-loop optimization without outerloop optimization, i.e., only fast weights except for slow weights are fine-tuned. In contrast, LifeLearner leverages the full potential of meta-learning by using both inner-and outer-loop optimization in the meta-testing phase. Specifically, our proposed meta-testing procedure starts with the inner-loop weight updates to learn new classes swiftly using a few samples (Lines 5-6), followed by the outer-loop weight updates to retain the knowledge on the previously learned classes using the replayed samples plus the new samples (Line 8). Note that although the outer-loop iteration could run multiple epochs, the performance converges after one or two epochs (refer to Section 5.4 for more analysis). Also, LifeLearner integrates the compression module that compresses (Lines 9-10) and decompresses (Line 7) the latent activations during outer-loop optimization, as described in Section 3.2. Our Contribution. Our method conceptually leverages existing concepts. We solve the challenge of incorporating these concepts in a coordinated, efficient end-to-end system (as discussed in Section 2.3). We achieve higher accuracy than baselines while reducing the memory footprint drastically. Our key contributions are (1) co-designing the algorithmic innovation (rehearsal strategy) with an intelligent combination of lossless (bitmap) and lossy (PQ) compression to significantly reduce the resource requirements of CL and latent replay samples (Section 3), (2) successfully deploying LifeLearner end-to-end on two embedded devices and MCU on which many prior works fail to run (Section 4). We develop the first phase, meta-training, of Meta CL methods on a Linux server to initialize the neural weights that can enable fast adaptation during deployment scenarios. After that, for the second phase, meta-testing, (i.e., actual deployment scenarios), we implemented our hardware-aware system by considering the hardware capacity and unique runtime characteristics of our target devices: (1) embedded and mobile systems such as Jetson Nano and Raspberry Pi 3B+, and (2) a microcontroller unit such as STM32H747. To further optimize the system efficiency, we adopt hardware-friendly optimization techniques in our implementation  Microcontroller Unit (MCU). To demonstrate the feasibility of the broader deployment of CL systems at the extreme edge, we further optimized and developed LifeLearner on MCUs. We implemented the online component of LifeLearner using C++ on an STM32H747 device equipped with ARM Cortex M4 and M7 cores with 1MB SRAM and 2 MB eFlash in total. However, we only utilize one core (ARM Cortex M7), as most MCUs have one CPU core. Also, we restrict the usage space of SRAM and eFlash to 512 KB and 1 MB, respectively, to enforce stricter resource constraints (an order of magnitude smaller memory space than other embedded devices with larger than 1 GB RAM). To deploy LifeLearner on MCUs effectively and efficiently, we addressed many technical challenges and considered hardware characteristics. First of all, the memory requirements of the MetaCL methods developed on embedded devices, including LifeLearner, far exceed the hardware capacity of a \"high-end\" MCU such as STM32H747 (refer to Section 5.2). Hence, we first searched for a smaller yet accurate architecture for MCUs by experimenting with various width modifiers  We then implemented our Compression Module (sparse bitmap compression and PQ) to reduce memory usage of latent replay samples on SRAM. In particular, we consider hardware characteristics and constraints: (1) the write operation on the storage (Flash) of MCUs is costly  In addition, we rely on the TFLM framework  Lastly, the binary size of our Compression Module and Backpropagation Engine, excluding C++ Standard Library (STL) on an MCU, is only 80 KB, introducing minimal overhead on storage. Hardware-friendly Optimization. We further optimize Life-Learner's CL operations on-device. By freezing the model's feature extractor during deployment, LifeLearner significantly reduces the computational cost for the already learned classes during replay by omitting the forward and backward passes. In addition, we utilize the hardware-friendly 8-bit integer arithmetic  We briefly describe our experimental setup in this subsection. As in  We employ three datasets of two different data modalities in our evaluation. CIFAR-100  MiniImageNet  GSCv2  We compare our system, LifeLearner, with five baseline systems as follows. Oracle: The CL performance of Oracle represents the upper bound performance of the experiments. It is because Oracle has access to all the classes at once in an i.i.d. fashion and performs DNN training for many epochs until the performance converges. Pretrained: This baseline initializes the model weights based on conventional DNN training without the meta-learning procedure. Then, it finetunes the weights using given samples in the meta-test phase, similar to prior Meta CL methods. OML+AIM  ANML  ANML+AIM  LifeLearner employs the network architecture used in the prior CL works for a fair comparison  the model architecture described above is adopted for the MCU deployment (see Section 5.5 for details). We followed the meta-training procedure used in prior Meta CL works  Accuracy. We start by evaluating the CL performance (testing accuracy) of LifeLearner compared to the baselines on the employed datasets. Figure  Table  Although LifeLearner shows a slightly lower accuracy for GSCv2 than ANML+AIM, it still outperforms ANML+AIM by 4.1% on average over all datasets. In addition, LifeLearner is essentially designed for edge devices to require drastically lower system resources (memory, latency, and energy) than the previous SOTA. As explained in the following, the excessive resource overhead of ANML+AIM makes it unsuitable to operate on resource-constrained devices. Peak Memory Footprint. We investigate the peak memory footprint required to perform CL. Precisely, we measure the memory space required to perform backpropagation and to store rehearsal samples. The memory requirement to perform backpropagation consists of three components: (1) model memory that stores model parameters, (2) optimizer memory that stores gradients and momentum vectors, and (3) activation memory that is comprised of the intermediate activations (stored for reuse during backpropagation). Then, the memory requirement for rehearsal samples is included. Table  We first measure the end-to-end latency of our system and the baselines on Jetson Nano CPU to perform CL over all the given classes with 30 samples per class. As shown in Figures  To measure the energy consumption, we first use Tegrastats on Jetson Nano to measure the power consumption. Then, we calculate the energy consumption by multiplying power consumption and the elapsed time for each end-to-end CL trial. Similar to the latency results, Figures  Summary. Our result demonstrates that LifeLearner can effectively learn new classes in a continual manner based on only a few samples without experiencing catastrophic forgetting, i.e., it generalizes well to new samples of many classes unseen during the offline learning phase. Moreover, LifeLearner enables fast and energy-efficient CL on edge devices with significantly reduced memory footprint. We perform an ablation study to investigate the role of each component of our system by incrementally adding our proposed components on top of the baseline system (ANML): (1) rehearsal strategy with inner-and outer-loop optimization (Latent), (2) sparse bitmap compression (Latent+Bit), (  Effect of Rehearsal with Double-Loop Optimization. As shown in Table  Effect of Compression and Hardware-aware Implementation. The results of various CL systems such as Latent+Bit, La-tent+PQ, and Latent+Bit+PQ show that the proposed compression techniques for latent representations do not sacrifice the accuracy of the CL systems but reduce the overall memory footprint compared to Latent. Moreover, our Compression Module incurs small Overall, the ablation study reveals that the co-utilization of the rehearsal strategy with double-loop optimization, Compression Module, and hardware-friendly implementation effectively makes LifeLearner more accurate and efficient. Next, we study the impact of the various hyper-parameters that could affect the performance of our system (see Figure  The Number of Given Samples. We first examine the accuracy of LifeLearner according to the number of given samples per class (ranging from 10 to 30) as it would directly affect labeling effort of users (see Figure  The Number of Replay Epochs. We study to what extent the number of replay epochs affects the CL performance as more epochs Figure  incur larger latency and energy consumption. Figure  These results show that with only 10-30 samples per class, Life-Learner achieve similar CL performance to Oracle, exhibit rapid convergence with small replay epochs (at most two), and accomplish a high compression rate for rehearsal samples. TinyANML Architecture. For the extremely resource constrained IoT devices like MCUs where on-chip memory of SRAM and Flash are typically a few hundred KB or 1 MB at most (an order of magnitude smaller than Jetson Nano and Pi 3B+ in terms of memory), the memory requirements of the MetaCL methods, including Life-Learner, are prohibitively large. Thus, we propose a small and accurate TinyANML architecture designed for MCUs with tiny memory by experimenting with various width modifiers  MCU Implementation and Results. Backbone represents an inference-only feature extractor based on TFLM. On top of that, our hardware-aware systems are added incrementally: (1) Backpropagation Engine (Tiny ANML) and (2) Compression Module (Tiny LifeLearner). Table  Co-design of Our Algorithm and Hardware-aware System Implementation. Tiny LifeLearner not only largely prevents accuracy degradation compared to its original LifeLearner (see Table  Note that it is infeasible to perform the ablation study to quantify the benefits of our design as in Section 5.3. This is because other baselines with rehearsal strategy and prior works exhibit out-of-memory problems and only tiny LifeLearner could run on MCUs with severely limited memory. Impact on Continual Learning. We envision that LifeLearner could make CL a practical reality on embedded and IoT devices by leveraging meta-learning and rehearsal strategy with only a few samples. Such CL systems will allow DNNs to add new classes (e.g., adding new objects to an image recognition system, adding new keywords to a voice assistant) or new modalities (e.g., adding image recognition on top of a voice recognition authentication system) on the fly without relying on the cloud (i.e., no communication costs). As one future direction, further optimizing LifeLearner to use stricter quantization such as 1, 2, or 4 bits will be interesting. Generalizability of LifeLearner. LifeLearner successfully works on three different datasets operating on two different modalities: image and audio, showing the generalizability of our framework. With the proliferation of smart spaces, such as smart homes and offices, LifeLearner can be used to learn the personal habits and preferences of users in order to control environmental conditions, such as temperature, humidity and lighting, with readings coming from thermometers, motion sensors and cameras on IoT devices. LifeLearner would enable this personalization and space adaptivity to happen in a data-efficient manner and to stay local to ensure privacy. Moreover, LifeLearner could be used on robot vacuum cleaners to enhance their adaptability, e.g., to continually learn to visually recognize new objects and thus avoid collisions. The evaluation of other datasets and potentially other modalities, including various other sensor signals  Scalibility over Many Classes. The sample-wise compression ratio of LifeLearner is about 30\u00d7, significantly reducing the memory overhead of adding many classes. It incurs only 1.68 MB, 6.16 MB, and 0.66 MB of memory when adding 100 classes with 30 samples per class for CIFAR-100, MiniImageNet, and GSCv2, respectively. Also, our scalar quantization and selective layer updates resolve scalability issues of latency as it incurs minimal latency overhead over ANML with fixed latency to learn new classes (see Tables  Feasibility of Labeling Samples. One of the key challenges of enabling realistic applications for CL is annotation difficulty by users. As conventional CL typically demands a few thousand labeled samples, it becomes almost infeasible for users to perform labeling (as discussed in Section 2.1). Instead, LifeLearner ameliorates this labeling burden by enabling data-efficient CL with 10-30 samples per class which are not impractical to label. Other Considerations. In this work, our evaluation demonstrated that LifeLearner achieves near-optimal CL performance, falling short by only 2.8% accuracy compared to the upper bound system (Oracle). However, a higher accuracy (over 80-90%) given fewer samples (less than 10-30 samples) would be desirable. Thus, it is worth investigating larger and more advanced model architectures specializing in the target problem and task, such as Transformers  We proposed LifeLearner, a hardware-aware meta CL system with adaptive fast-slow weights and resource-optimized compression for embedded and IoT platforms. LifeLearner outperforms all existing Meta CL methods by a large margin (approximating the upper bound method that performs training in i.i.d. setting) and demonstrates its potential applicability in real-world deployments. Our efficient CL system opens the door to adaptive applications to run on embedded and IoT devices by allowing them to learn new tasks and adapt to the dynamics of the user and context."
}